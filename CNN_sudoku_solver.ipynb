{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test puzzles\n",
    "with open('sudoku_test.pkl', 'rb') as f:\n",
    "    unsolved_test, solved_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train puzzles\n",
    "with open('sudoku.pkl', 'rb') as f:\n",
    "    unsolved, solved = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_solver_enhanced(x, y):\n",
    "    '''Model with three convolutional layers. Number of filtres are doubled within each layer''' \n",
    "    # Set up the model\n",
    "    solver = models.Sequential()\n",
    "    # Add convolutional layer with 64 filters\n",
    "    solver.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(9, 9, 1), padding='same'))\n",
    "    solver.add(layers.BatchNormalization())\n",
    "    # Add convolutional layer with 128 filters\n",
    "    solver.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    solver.add(layers.BatchNormalization())\n",
    "    # Add convolutional layer with 256 filters\n",
    "    solver.add(layers.Conv2D(256, (1, 1), activation='relu', padding='same'))\n",
    "    \n",
    "    # Prepare output of convolutional layers for densely connected network by flattening out data\n",
    "    solver.add(layers.Flatten())\n",
    "    # Add densely connected neural network\n",
    "    solver.add(layers.Dense(729))\n",
    "    solver.add(layers.Reshape((-1,9)))\n",
    "    # Choose activation function\n",
    "    solver.add(layers.Activation('softmax'))\n",
    "    # Choose optimizer and fit model\n",
    "    optimizer_ad = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    solver.compile(ArithmeticErroroptimizer=optimizer_ad,loss='sparse_categorical_crossentropy')\n",
    "    solver.fit(x, y, batch_size=100, epochs=2)\n",
    "    \n",
    "    # Save model\n",
    "    solver.save('cnn_sudoku_model_enhanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_solver_reduced(x, y):\n",
    "    '''\n",
    "    Model with two convolutional layers. Number of filtres remains the same\n",
    "    It goes through 3 epochs\n",
    "    '''\n",
    "    # Set up the model\n",
    "    solver = models.Sequential()\n",
    "    # Add convolutional layer with 64 filters\n",
    "    solver.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(9, 9, 1), padding='same'))\n",
    "    solver.add(layers.BatchNormalization())\n",
    "    # Add convolutional layer with 64 filters\n",
    "    solver.add(layers.Conv2D(64, (1, 1), activation='relu', padding='same'))\n",
    "    \n",
    "    # Prepare output of convolutional layers for densely connected network by flattening out data\n",
    "    solver.add(layers.Flatten())\n",
    "    # Add densely connected neural network\n",
    "    solver.add(layers.Dense(729))\n",
    "    solver.add(layers.Reshape((-1,9)))\n",
    "    # Choose activation function\n",
    "    solver.add(layers.Activation('softmax'))\n",
    "    # Choose optimizer and fit model\n",
    "    optimizer_ad = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    solver.compile(optimizer=optimizer_ad,loss='sparse_categorical_crossentropy')\n",
    "    solver.fit(x, y, batch_size=100, epochs=3)\n",
    "    \n",
    "    # Save model\n",
    "    solver.save('cnn_sudoku_model_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model\n",
    "unsolved_prepared = np.asarray([np.asarray((x/9) - 0.5).reshape(9,9,-1) for x in unsolved])\n",
    "solved_prepared = np.asarray([np.asarray(x-1).reshape(81,-1) for x in solved])\n",
    "\n",
    "unsolved_test_prepared = np.asarray([np.asarray((x/9) - 0.5).reshape(9,9,-1) for x in unsolved_test])\n",
    "solved_test_prepared = np.asarray([np.asarray(x-1).reshape(81,-1) for x in solved_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500000/500000 [==============================] - 2510s 5ms/sample - loss: 0.4448\n",
      "Epoch 2/2\n",
      "500000/500000 [==============================] - 2616s 5ms/sample - loss: 0.2611\n"
     ]
    }
   ],
   "source": [
    "# Enhanced solver training\n",
    "cnn_solver_enhanced(unsolved_prepared, solved_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500000/500000 [==============================] - ETA: 0s - loss: 0.5855- ETA: 1s - lo - 832s 2ms/sample - loss: 0.5854\n",
      "Epoch 2/3\n",
      "500000/500000 [==============================] - 920s 2ms/sample - loss: 0.2870\n",
      "Epoch 3/3\n",
      "500000/500000 [==============================] - 921s 2ms/sample - loss: 0.2607\n"
     ]
    }
   ],
   "source": [
    "# Reduced solver training\n",
    "cnn_solver_reduced(unsolved_prepared, solved_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sudoku(puzzle, model):\n",
    "    '''Function for solving sudoku puzzles''' \n",
    "    # Map missing values\n",
    "    map_missing = ((puzzle == -0.5).reshape(9,9))\n",
    "    \n",
    "    # Loop while there are values to be filled in the puzzle\n",
    "    while map_missing.sum() > 0:\n",
    "        # Let model make a prediction\n",
    "        output = model.predict(puzzle.reshape(-1,9,9,1)).squeeze()\n",
    "        # Each position in sudoku grid has now assigned set of probabilities of possible entries (numbers from 1 to 9)\n",
    "        \n",
    "        # Returns maximum probability from each set of probabilities\n",
    "        max_probability = np.around(np.max(output, axis=1).reshape((9,9)), 3)\n",
    "        # Return correspongind prediction from each set\n",
    "        predictions = np.argmax(output, axis=1).reshape(9,9)+1\n",
    "        \n",
    "        # Map all unknown numbers \n",
    "        map_missing_prob = max_probability * map_missing\n",
    "        \n",
    "        # Find a position in sudoku grid where the model is most certaint about predicted value\n",
    "        index_max_prob = np.argmax(map_missing_prob)\n",
    "        \n",
    "        # Find x and y coordinates\n",
    "        x = index_max_prob // 9\n",
    "        y = index_max_prob % 9\n",
    "        \n",
    "        # Select predicted value which will be inported to the solution\n",
    "        predicted_value = predictions[x][y]\n",
    "        \n",
    "        # Add predicted value to correct position \n",
    "        puzzle[x][y] = (predicted_value / 9) - 0.5\n",
    "        # Update map of missing values\n",
    "        map_missing = ((puzzle == -0.5).reshape(9,9))\n",
    "    \n",
    "    # Convert normalized values back to numbers\n",
    "    puzzle_with_numbers = (puzzle + 0.5) * 9\n",
    "    \n",
    "    return puzzle_with_numbers.reshape(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(x_test, y_test, model):\n",
    "    '''Function for evaluating sudoku solver accuracy''' \n",
    "    solved = 0\n",
    "    \n",
    "    for i, game in enumerate(x_test):\n",
    "        \n",
    "        prediction = predict_sudoku(game, model)\n",
    "\n",
    "        if np.array_equal(prediction, y_test[i]):\n",
    "            solved += 1\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    return solved / len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Honza\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Honza\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Honza\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# Lead enhanced model\n",
    "model_enhanced = models.load_model('cnn_sudoku_model_enhanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reduced model\n",
    "model_reduced = models.load_model('cnn_sudoku_model_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7282"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanced model evaluation\n",
    "acc(unsolved_test_prepared, solved_test, model_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7148"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduced model evaluation\n",
    "acc(unsolved_test_prepared, solved_test, model_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "Accuracy of both models was 72.82 %. This is not much. However accuracy score was raised only if the predicted sudoku actualy matched with corresponding test sudoku. As the sudoku was randomly generated, there may be more correct solutions for one puzzle. In upcomming sections each sudoku is checked with respect to actual game rules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grid_by_rules(grid):\n",
    "    grid_t = np.transpose(grid)\n",
    "    grid_split_h = np.hsplit(grid, 3)\n",
    "    grid_split_1 = np.split(grid_split_h[0], 3)\n",
    "    grid_split_2 = np.split(grid_split_h[1], 3)\n",
    "    grid_split_3 = np.split(grid_split_h[2], 3)\n",
    "    \n",
    "    for number in range(1,10):\n",
    "        for i in range(9):\n",
    "            if np.isin(grid[i], number).sum() > 1 or np.isin(grid[i], number).sum() == 0:\n",
    "                return 0\n",
    "            if np.isin(grid_t[i], number).sum() > 1 or np.isin(grid_t[i], number).sum() == 0:\n",
    "                return 0\n",
    "        for j in range(3):\n",
    "            if np.isin(grid_split_1[j], number).sum() > 1 or np.isin(grid_split_1[j], number).sum() == 0:\n",
    "                return 0\n",
    "            if np.isin(grid_split_2[j], number).sum() > 1 or np.isin(grid_split_2[j], number).sum() == 0:\n",
    "                return 0\n",
    "            if np.isin(grid_split_3[j], number).sum() > 1 or np.isin(grid_split_3[j], number).sum() == 0:\n",
    "                return 0\n",
    "        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sudoku_correct_check(games, model):\n",
    "    correct = 0\n",
    "    \n",
    "    for i,game in enumerate(games):\n",
    "        \n",
    "        pred = predict_sudoku(game, model)\n",
    "        \n",
    "        correct += check_grid_by_rules(pred)\n",
    "    \n",
    "    print(correct/games.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models by sudoku rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972\n"
     ]
    }
   ],
   "source": [
    "# Enhanced model\n",
    "sudoku_correct_check(unsolved_test_prepared[0:1000], model_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n"
     ]
    }
   ],
   "source": [
    "# Reduced model\n",
    "sudoku_correct_check(unsolved_test_prepared[0:1000], model_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
